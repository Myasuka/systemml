//
// From CSV w/ header line to MTX and MTD
//
//  author: Berthold Reinwald, Aug. 2012
//


//
// JsonLines
//
jsonLines = fn(location)
  lines( location,
        inoptions = { converter:
        "com.ibm.jaql.io.hadoop.converter.FromJsonTextConverter"},
        outoptions = { converter:
        "com.ibm.jaql.io.hadoop.converter.ToJsonTextConverter"});



//
// Parallel Enumerate
//

// helper function for parallel enumeration

runningSum = fn(input, dataFn, intoFn)
   input -> runningCombine(0, fn(sum,i) sum + dataFn(i), intoFn);

worklist = fn(array)
  { type: 'array', inoptions: { array }};

parallelEnumerate = fn(fd)
(
   annotatedSplits =
      read( worklist(inputSplits(fd)) )
      -> transform each split { split, n: readSplit(fd, split) -> count()}
      -> runningSum( fn(i) i.n, fn(sum,i) { i.split, n: sum - i.n } ),

      read (worklist(annotatedSplits))
      -> expand each s (readSplit(fd, s.split) -> enumerate() -> transform
      [s.n+$[0], $[1]])
);


//
// CSV row to sparse IJV
//
RowToSparseIJV = fn (row)
(
   // assumption is that 0-th slot in array is the rowid and it does not
   // explicitly be turned into a column

   row
      // verticalize, i.e. <rid, v>
   -> transform [row[0], $]
      // add colId, i.e. <colId, <rid, v>>
   -> enumerate()
      // produce <ColId, rid, v>
   -> transform union(toArray($[0]), $[1])
      // filter "0" values for sparsity
   -> filter double( $[2]) != 0
      // filter column for colId
   -> filter $[0] != 0
      // produce <rid, cid, v>
   -> transform [$[1], $[0], double($[2])]
);


//
// Frame to SparseMatrix: write sparse matrix (i.e. enum rowid/colid) and mtd file
//
FrameToSparseMatrix = fn (fname)
(
  // strip last file extension
  out_fname= substring(fname, 0, strPosList( fname, ".")[count(strPosList( fname, "."))-1]),

  parallelEnumerate(del( fname))
  -> transform union(toArray($[0]+1), $[1])
  -> tee(
  		  -> group into
              {
                data_type : "matrix"
               ,value_type: "double"
               ,rows      : max($[*][0])
               ,cols      : count($[0]) - 1
				// !! computation of nnz is too slow (single reducer)
               ,nnz       : $ -> transform removeElement ($[*], 0) -> expand ($) -> filter double($) != 0 -> count()
               ,format    : "text"
              }
          -> write (jsonLines(out_fname + ".mtx.mtd"))
        )
  -> expand RowToSparseIJV( $)
  -> write(del( out_fname + ".mtx", {delimiter: " ", schema:schema[long,long,double]}))
);


