#-------------------------------------------------------------
# IBM Confidential
# OCO Source Materials
# (C) Copyright IBM Corp. 2010, 2014
# The source code for this program is not published or
# otherwise divested of its trade secrets, irrespective of
# what has been deposited with the U.S. Copyright Office.
#-------------------------------------------------------------

setwd ("test/scripts/applications/glm");
# source ("Cholesky.dml");
source ("CGSteihaug.dml");
source ("Misc.dml");

# Intended to solve GLM Regression using Iteratively Reweighted Least Squares WITH TRUST REGIONS
# Assume LR_HOME is set to the home of the dml script
# Assume input and output directories are on hdfs as INPUT_DIR and OUTPUT_DIR
# INPUT  1: Matrix X [rows, columns]
# INPUT  2: Matrix y [rows, 1], or [rows, 2] for "Binomial Two-Column (#pos, #neg)"
# INPUT  3: (Int) Distribution Family Type: 1 = Power, 2 = Binomial
# INPUT  4: (Double) Distribution Parameter, see table below
#             For Power Families - the power in Variance-of-the-Mean function:
#             0.0 = Gaussian, 1.0 = Poisson, 2.0 = Gamma, 3.0 = Inverse Gaussian
# INPUT  5: (Int) Link Function: 0 = Canonical (depends on the distribution),
#             1 = Power, 2 = Logit, 3 = Probit, 4 = Cloglog, 5 = Cauchit
# INPUT  6: (Double) Power in Link-of-the-Mean function (for Power Link):
#             -2.0 = 1/mu^2, -1.0 = reciprocal, 0.0 = log, 0.5 = sqrt, 1.0 = identity 
# INPUT  7: (Double) Overdispersion: <=0.0: estimate, >0.0: use this value
# INPUT  8: (Double) L2-regularizer (lambda)
# INPUT  9: (Double) Tolerance (epsilon)
# INPUT 10: The output file
#
# OUTPUT  : Matrix beta [cols, 1]
#
# Assume distribution family = "Binomial.logit", overdispersion = 0.0, lambda = 0.0, epsilon = 0.00000001
# hadoop jar SystemML.jar -f $GLM_HOME/GLM.dml -args "$INPUT_DIR/X" "$INPUT_DIR/y" 2 -1.0 2 0.0 0.0 0.0 0.00000001 "$OUTPUT_DIR/beta"
#
# SUPPORTED GLM DISTRIBUTION FAMILIES AND LINKS:
# ---------------------------------------------
#   Dst Var Lnk Lnk   Distribution       Cano-
#   typ pow typ pow   Family.link        nical?
# ---------------------------------------------
#    1  0.0  1 -1.0   Gaussian.inverse
#    1  0.0  1  0.0   Gaussian.log
#    1  0.0  1  1.0   Gaussian.id         Yes
#    1  1.0  1  0.0   Poisson.log         Yes
#    1  1.0  1  0.5   Poisson.sqrt
#    1  1.0  1  1.0   Poisson.id
#    1  2.0  1 -1.0   Gamma.inverse       Yes
#    1  2.0  1  0.0   Gamma.log
#    1  2.0  1  1.0   Gamma.id
#    1  3.0  1 -2.0   InvGaussian.1/mu^2  Yes
#    1  3.0  1 -1.0   InvGaussian.inverse
#    1  3.0  1  0.0   InvGaussian.log
#    1  3.0  1  1.0   InvGaussian.id
#    1   *   1   *    AnyVariance.AnyLink
# ---------------------------------------------
#    2 -1.0  *   *    Binomial {-1, 1}
#    2  0.0  *   *    Binomial { 0, 1}
#    2  1.0  *   *    Binomial two-column
#    2   *   1  0.0   Binomial.log
#    2   *   2   *    Binomial.logit      Yes
#    2   *   3   *    Binomial.probit
#    2   *   4   *    Binomial.cloglog
#    2   *   5   *    Binomial.cauchit
# ---------------------------------------------


print("BEGIN GLM SCRIPT");
print("Reading X...");
X = read($1, format="text");
print("Reading Y...");
y = read($2, format="text");

num_records  = nrow(X);
num_features = ncol(X);

distribution_type = $3;
distribution_parameter = $4;
link_type = $5;
link_as_power_of_the_mean = $6;
overdispersion = $7;
lambda_regularizer = $8;
eps = $9;

# Set up the canonical link, if requested [Then we have: Var(mu) * (d link / d mu) = const]
if (link_type == 0)
{
    if (distribution_type == 1) {
        link_type = 1;
        link_as_power_of_the_mean = 1.0 - distribution_parameter;
    } else { if (distribution_type == 2) {
            link_type = 2;
}   }   }

# For power distributions and/or links, we use two constants,
# "distribution_parameter" that here represents "variance as power
# of the mean", and "link_as_power_of_the_mean", to specify the
# variance and the link as arbitrary powers of the mean.  However,
# the variance-powers of 1.0 (Poisson family) and 2.0 (Gamma
# family) have to be treated as special cases, because these
# values integrate into logarithms.  The link-power of 0.0 is also
# special as it represents the logarithm link.


is_supported = check_if_supported (y, distribution_type, distribution_parameter, link_type, link_as_power_of_the_mean);
if (is_supported == 1)
{

#####   INITIALIZE THE BETAS   #####

[beta, saturated_log_l, isNaN] = 
    glm_initialize (X, y, distribution_type, distribution_parameter, link_type, link_as_power_of_the_mean, lambda_regularizer);
if (isNaN == 0)
{

#####  START OF THE MAIN PART  #####

max_trust_delta = sqrt (1.0 + num_features);
trust_delta = max_trust_delta / 100.0;
g = matrix (0.0, rows = num_features, cols = 1);
A = matrix (0.0, rows = num_features, cols = num_features);
log_l = 0.0;
deviance_nodisp = 0.0;
new_deviance_nodisp = 0.0;
isNaN_log_l = 2;
newbeta = beta;
accept_new_beta = 1;
reached_trust_boundary = 0;
neg_log_l_change_predicted = 0.0;
max_iteration_IRLS = 200;
converged_IRLS = 0;
i_IRLS = 0;

print ("BEGIN IRLS ITERATIONS...");

all_linear_terms = X %*% newbeta;

[new_log_l, isNaN_new_log_l] = glm_log_likelihood_part
    (all_linear_terms, y, distribution_type, distribution_parameter, link_type, link_as_power_of_the_mean);

if (isNaN_new_log_l == 0) {
    new_deviance_nodisp = 2.0 * (saturated_log_l - new_log_l);
    new_log_l = new_log_l - 0.5 * lambda_regularizer * sum (newbeta * newbeta);
}
                             

while (converged_IRLS == 0)
{
    accept_new_beta = 1;
    
    if (i_IRLS > 0)
    {
        if (isNaN_log_l == 0) {
            accept_new_beta = 0;
        }

# Decide whether to accept a new iteration point and update the trust region
# See Alg. 4.1 on p. 69 of "Numerical Optimization" 2nd ed. by Nocedal and Wright

        rho = (- new_log_l + log_l) / neg_log_l_change_predicted;
        if (rho < 0.25 | isNaN_new_log_l == 1) {
            trust_delta = 0.25 * trust_delta;
        }
        if (rho > 0.75 & isNaN_new_log_l == 0 & reached_trust_boundary == 1) {
            trust_delta = 2 * trust_delta;
            if (trust_delta > max_trust_delta) {
                trust_delta = max_trust_delta;
            }
        }
        if (rho > 0.1 & isNaN_new_log_l == 0) {
            accept_new_beta = 1;
        }
    }

    if (accept_new_beta == 1)
    {
        beta = newbeta;  log_l = new_log_l;  deviance_nodisp = new_deviance_nodisp;  isNaN_log_l = isNaN_new_log_l;
        [y_mean, link_grad, y_var] = 
            glm_dist (all_linear_terms, y, distribution_type, distribution_parameter, link_type, link_as_power_of_the_mean);
                      
# norm_y_mean = sqrt (sum (y_mean * y_mean));
# norm_y_var = sqrt (sum (y_var * y_var));
# norm_link_grad = sqrt (sum (link_grad * link_grad));
# min_linear_term = min (all_linear_terms);
# max_linear_term = max (all_linear_terms);
# print ("||y_mean|| = " + norm_y_mean + ";  ||y_var|| = " + norm_y_var + ";  ||link_grad|| = " + norm_link_grad + ";  max_linear_term = " + max_linear_term);                      
                      
        aux_diag = matrix (1.0, rows = num_records, cols = 1);
        aux_diag = (aux_diag / y_var) / link_grad;
        g = - t(X) %*% (aux_diag * (y [, 1] - y_mean));
        w_diag = aux_diag / link_grad;
        A = t(X) %*% diag (w_diag) %*% X;
    }
    
    [z, neg_log_l_change_predicted, reached_trust_boundary] = 
        get_CG_Steihaug_point (A, g, beta, trust_delta, lambda_regularizer);

    newbeta = beta + z;
    
    all_linear_terms = X %*% newbeta;
    
    [new_log_l, isNaN_new_log_l] = glm_log_likelihood_part
        (all_linear_terms, y, distribution_type, distribution_parameter, link_type, link_as_power_of_the_mean);

    if (isNaN_new_log_l == 0) {
        new_deviance_nodisp = 2.0 * (saturated_log_l - new_log_l);
        new_log_l = new_log_l - 0.5 * lambda_regularizer * sum (newbeta * newbeta);
    }
        
    log_l_change = new_log_l - log_l;               # R's criterion for termination: |dev - devold|/(|dev| + 0.1) < eps

    if (reached_trust_boundary == 0 & isNaN_new_log_l == 0 & 
        (2.0 * abs (log_l_change) < eps * (deviance_nodisp + 0.1) | abs (log_l_change) < (abs (log_l) + abs (new_log_l)) * 0.00000000000001) )  
    {
        converged_IRLS = 1;
    }
    rho = - log_l_change / neg_log_l_change_predicted;
    z_norm = sqrt (sum (z * z));
    
    [z_norm_m, z_norm_e] = round_to_print (z_norm);
    [trust_delta_m, trust_delta_e] = round_to_print (trust_delta);
    [rho_m, rho_e] = round_to_print (rho);
    [new_log_l_m, new_log_l_e] = round_to_print (new_log_l);
    [log_l_change_m, log_l_change_e] = round_to_print (log_l_change);
    g_norm = sqrt (sum (g * g));
    [g_norm_m, g_norm_e] = round_to_print (g_norm);

    i_IRLS = i_IRLS + 1;
    print ("Iter #" + i_IRLS + " completed"
        + ", ||z|| = " + z_norm_m + "E" + z_norm_e
        + ", trust_delta = " + trust_delta_m + "E" + trust_delta_e
        + ", reached = " + reached_trust_boundary
        + ", ||g|| = " + g_norm_m + "E" + g_norm_e
        + ", new_log_l = " + new_log_l_m + "E" + new_log_l_e
        + ", log_l_change = " + log_l_change_m + "E" + log_l_change_e
        + ", rho = " + rho_m + "E" + rho_e);
    if (i_IRLS == max_iteration_IRLS) {
        converged_IRLS = 2;
    }
}

beta = newbeta;
log_l = new_log_l;
deviance_nodisp = new_deviance_nodisp;

if (converged_IRLS == 1) {
    print ("Converged in " + i_IRLS + " steps.");
} else {
    print ("Did not converge.");
}

print ("beta[1] = " + castAsScalar(beta[1, 1]));
print ("beta[2] = " + castAsScalar(beta[2, 1]));
print ("beta[3] = " + castAsScalar(beta[3, 1]));


write (beta, $10, format="text");



#####  OVER-DISPERSION PART  #####

all_linear_terms = X %*% beta;
[y_mean, link_grad, y_var] = 
    glm_dist (all_linear_terms, y, distribution_type, distribution_parameter, link_type, link_as_power_of_the_mean);
pearson_residuals = (y[, 1] - y_mean) / sqrt (y_var);

if (overdispersion <= 0.0)
{
    overdispersion = sum (pearson_residuals * pearson_residuals) / (num_records - num_features);
    print ("Estimated overdispersion = " + overdispersion);
}

deviance = deviance_nodisp / overdispersion;
print ("Deviance:  no overdispersion = " + deviance_nodisp + ",  with overdispersion = " + deviance);


#####  END OF THE MAIN PART  #####

} else { print ("Response vector is out of range.  Terminating the DML."); }
} else { print ("Distribution/Link not supported.  Terminating the DML."); }


check_if_supported = 
    function (Matrix[double] y, int dist_type, double dist_param, int link_type, double link_power)
    return   (int is_supported)
{
    is_supported = 0;
    ncol_y = ncol(y);
    if (ncol_y == 1 & dist_type == 1 & link_type == 1)
    { # POWER DISTRIBUTION
        is_supported = 1;
        var_power = dist_param;
        if (var_power == 0.0 & link_power == -1.0) {print ("Gaussian.inverse");      } else {
        if (var_power == 0.0 & link_power ==  0.0) {print ("Gaussian.log");          } else {
        if (var_power == 0.0 & link_power ==  1.0) {print ("Gaussian.id");           } else {
        if (var_power == 0.0                     ) {print ("Gaussian.power_nonlog"); } else {
        if (var_power == 1.0 & link_power ==  0.0) {print ("Poisson.log");           } else {
        if (var_power == 1.0 & link_power ==  0.5) {print ("Poisson.sqrt");          } else {
        if (var_power == 1.0 & link_power ==  1.0) {print ("Poisson.id");            } else {
        if (var_power == 1.0                     ) {print ("Poisson.power_nonlog");  } else {
        if (var_power == 2.0 & link_power == -1.0) {print ("Gamma.inverse");         } else {
        if (var_power == 2.0 & link_power ==  0.0) {print ("Gamma.log");             } else {
        if (var_power == 2.0 & link_power ==  1.0) {print ("Gamma.id");              } else {
        if (var_power == 2.0                     ) {print ("Gamma.power_nonlog");    } else {
        if (var_power == 3.0 & link_power == -2.0) {print ("InvGaussian.1/mu^2");    } else {
        if (var_power == 3.0 & link_power == -1.0) {print ("InvGaussian.inverse");   } else {
        if (var_power == 3.0 & link_power ==  0.0) {print ("InvGaussian.log");       } else {
        if (var_power == 3.0 & link_power ==  1.0) {print ("InvGaussian.id");        } else {
        if (var_power == 3.0                     ) {print ("InvGaussian.power_nonlog");}else{
        if (                   link_power ==  0.0) {print ("PowerDist.log");         } else {
                                                    print ("PowerDist.power_nonlog");  # TAKING THIS INSTRUCTION INTO {...} GIVES AN ERROR!
    }   }}}}} }}}}} }}}}} }}}
    if (ncol_y == 1 & dist_type == 2 & (dist_param == -1.0 | dist_param == 0.0) & link_type >= 1 & link_type <= 5)
    { # BERNOULLI DISTRIBUTION
        is_supported = 1;
        if (link_type == 1 & link_power == 0.0) {print ("Bernoulli.log");            } else {
        if (link_type == 1)                     {print ("Bernoulli.power_nonlog");   } else {
        if (link_type == 2)                     {print ("Bernoulli.logit");          } else {
        if (link_type == 3)                     {print ("Bernoulli.probit");         } else {
        if (link_type == 4)                     {print ("Bernoulli.cloglog");        } else {
        if (link_type == 5)                     {print ("Bernoulli.cauchit");        }
    }   }}}}}
    if (ncol_y == 2 & dist_type == 2 & dist_param == 1.0 & link_type >= 1 & link_type <= 5)
    { # BINOMIAL DISTRIBUTION
        is_supported = 1;
        if (link_type == 1 & link_power == 0.0) {print ("Binomial.log");             } else {
        if (link_type == 1)                     {print ("Binomial.power_nonlog");    } else {
        if (link_type == 2)                     {print ("Binomial.logit");           } else {
        if (link_type == 3)                     {print ("Binomial.probit");          } else {
        if (link_type == 4)                     {print ("Binomial.cloglog");         } else {
        if (link_type == 5)                     {print ("Binomial.cauchit");         }
    }   }}}}}
    if (is_supported == 0) {
        print ("Response matrix with " + ncol_y + " columns, distribution family (" + dist_type + ", " + dist_param
             + ") and link family (" + link_type + ", " + link_power + ") are NOT supported together.");
    }
}

glm_initialize = function (Matrix[double] X, Matrix[double] y,
                 int dist_type, double dist_param, int link_type, double link_power, double lambda)
return (Matrix[double] beta, double saturated_log_l, int isNaN)
{
    beta = matrix (0.0, rows = ncol(X), cols = 1);
    saturated_log_l = 0.0;
    isNaN = 0;
    y_corr = y [, 1];
    if (dist_type == 2 & dist_param == 1.0) {
        n_corr = rowSums (y);
        is_n_zero = ppred (n_corr, 0.0, "==");
        y_corr = y [, 1] / (n_corr + is_n_zero) + (0.5 - y [, 1]) * is_n_zero;
    } else { if (dist_type == 2 & dist_param != 1.0) {
        bernoulli_scale = 1.0 - dist_param;
        bernoulli_shift = dist_param;
        y_corr = (y [, 1] - bernoulli_shift) / bernoulli_scale;
    }}
    linear_terms = y_corr;
    if (dist_type == 1 & link_type == 1) { # POWER DISTRIBUTION
        if          (link_power ==  0.0) {
            if (sum (ppred (y_corr, 0.0, "<")) == 0) {
                is_zero_y_corr = ppred (y_corr, 0.0, "==");
                linear_terms = log (y_corr + is_zero_y_corr) - is_zero_y_corr / (1.0 - is_zero_y_corr);
            } else { isNaN = 1; }
        } else { if (link_power ==  1.0) {
            linear_terms = y_corr;
        } else { if (link_power == -1.0) {
            linear_terms = 1.0 / y_corr;
        } else { if (link_power ==  0.5) {
            if (sum (ppred (y_corr, 0.0, "<")) == 0) {
                linear_terms = sqrt (y_corr);
            } else { isNaN = 1; }
        } else { if (link_power >   0.0) {
            if (sum (ppred (y_corr, 0.0, "<")) == 0) {
                is_zero_y_corr = ppred (y_corr, 0.0, "==");
                linear_terms = (y_corr + is_zero_y_corr) ^ link_power - is_zero_y_corr;
            } else { isNaN = 1; }
        } else {
            if (sum (ppred (y_corr, 0.0, "<=")) == 0) {
                linear_terms = y_corr ^ link_power;
            } else { isNaN = 1; }
        }}}}}
    }
    if (dist_type == 2 & link_type >= 1 & link_type <= 5)
    { # BINOMIAL/BERNOULLI DISTRIBUTION
        if          (link_type == 1 & link_power == 0.0)  { # Binomial.log
            if (sum (ppred (y_corr, 0.0, "<")) == 0) {
                is_zero_y_corr = ppred (y_corr, 0.0, "==");
                linear_terms = log (y_corr + is_zero_y_corr) - is_zero_y_corr / (1.0 - is_zero_y_corr);
            } else { isNaN = 1; }
        } else { if (link_type == 1 & link_power >  0.0)  { # Binomial.power_nonlog pos
            if (sum (ppred (y_corr, 0.0, "<")) == 0) {
                is_zero_y_corr = ppred (y_corr, 0.0, "==");
                linear_terms = (y_corr + is_zero_y_corr) ^ link_power - is_zero_y_corr;
            } else { isNaN = 1; }
        } else { if (link_type == 1)                      { # Binomial.power_nonlog neg
            if (sum (ppred (y_corr, 0.0, "<=")) == 0) {
                linear_terms = y_corr ^ link_power;
            } else { isNaN = 1; }
        } else { 
            is_zero_y_corr = ppred (y_corr, 0.0, "<=");
            is_one_y_corr  = ppred (y_corr, 1.0, ">=");
            y_corr = y_corr * (1.0 - is_zero_y_corr) * (1.0 - is_one_y_corr) + 0.5 * (is_zero_y_corr + is_one_y_corr);
            if (link_type == 2)                           { # Binomial.logit
                linear_terms = log (y_corr / (1.0 - y_corr)) 
                    + is_one_y_corr / (1.0 - is_one_y_corr) - is_zero_y_corr / (1.0 - is_zero_y_corr);
            } else { if (link_type == 3)                  { # Binomial.probit
                y_below_half = y_corr + (1.0 - 2.0 * y_corr) * ppred (y_corr, 0.5, ">");
                t = sqrt (- 2.0 * log (y_below_half));
                approx_inv_Gauss_CDF = - t + (2.515517 + t * (0.802853 + t * 0.010328)) / (1.0 + t * (1.432788 + t * (0.189269 + t * 0.001308)));
                linear_terms = approx_inv_Gauss_CDF * (1.0 - 2.0 * ppred (y_corr, 0.5, ">"))
                    + is_one_y_corr / (1.0 - is_one_y_corr) - is_zero_y_corr / (1.0 - is_zero_y_corr);
            } else { if (link_type == 4)                  { # Binomial.cloglog
                linear_terms = log (- log (1.0 - y_corr))
                    - log (- log (0.5)) * (is_zero_y_corr + is_one_y_corr)
                    + is_one_y_corr / (1.0 - is_one_y_corr) - is_zero_y_corr / (1.0 - is_zero_y_corr);
            } else { if (link_type == 5)                  { # Binomial.cauchit
                linear_terms = tan ((y_corr - 0.5) * 3.1415926535897932384626433832795)
                    + is_one_y_corr / (1.0 - is_one_y_corr) - is_zero_y_corr / (1.0 - is_zero_y_corr);
        }}  }}}}}
    }
    
    if (isNaN == 0) {
        [saturated_log_l, isNaN] = 
            glm_log_likelihood_part (linear_terms, y, dist_type, dist_param, link_type, link_power);
    }
    
    flat_linear_terms = matrix (0.0, rows = nrow (linear_terms), cols = 1);
    if (link_type == 1 & link_power == 0.0) {
        flat_linear_terms = flat_linear_terms + log (0.5);
    } else { if (link_type == 1) {
        flat_linear_terms = flat_linear_terms + (0.5 ^ link_power);
    } else {
        flat_linear_terms = flat_linear_terms + 0.5;
    }}
    A_LS = t(X) %*% X;
    b_LS = - t(X) %*% flat_linear_terms;
    eps_LS = 0.000001 * sum (b_LS * b_LS);
    beta = get_simpleLS_point (A_LS, b_LS, lambda, eps_LS);
        
#       if (shrink_linear_terms_spread == 1) {
#           linear_terms = X %*% beta;
#           meanLF = sum (linear_terms) / nrow (linear_terms);
#           [beta, sigmaLF] = scaleWeights (X, beta, meanLF, 0.0);
#       }

}


glm_dist = function (Matrix[double] linear_terms, Matrix[double] y,
                     int dist_type, double dist_param, int link_type, double link_power)
    return (Matrix[double] y_mean, Matrix[double] link_gradient, Matrix[double] var_function)
    # NOTE: var_function is the variance without dispersion, i.e. the V(mu) function.
{
    y_mean = linear_terms;
    link_gradient = matrix (1.0, rows = nrow (linear_terms), cols = 1);
    var_function = link_gradient;
    
    if (dist_type == 1 & link_type == 1) { # POWER DISTRIBUTION
        var_power = dist_param;
        if          (link_power ==  0.0) {
            y_mean = exp (linear_terms);
            link_gradient = 1.0 / y_mean;
        } else { if (link_power ==  1.0) {
            y_mean = linear_terms;
            link_gradient = matrix (1.0, rows = nrow (linear_terms), cols = 1);
        } else { if (link_power == -1.0) {
            y_mean = 1.0 / linear_terms;
            link_gradient = - linear_terms * linear_terms;
        } else { if (link_power ==  0.5) {
            y_mean = linear_terms * linear_terms;
            link_gradient = 0.5 / linear_terms;        
        } else {
            y_mean = linear_terms ^ (1.0 / link_power);
            link_gradient = link_power * linear_terms ^ (1.0 - 1.0 / link_power);        
        }}}}
        if (var_power == 0.0) {
            var_function = matrix (1.0, rows = nrow (y_mean), cols = 1);
        } else { if (var_power == 1.0) {
            var_function = y_mean;
        } else { if (var_power == 2.0) {
            var_function = y_mean * y_mean;
        } else { if (var_power == 3.0) {
            var_function = y_mean * y_mean * y_mean;
        } else {
            var_function = y_mean ^ var_power;
        }}}}
    }
    if (dist_type == 2 & (dist_param == -1.0 | dist_param == 0.0 | dist_param == 1.0) & link_type >= 1 & link_type <= 5)
    { # BINOMIAL/BERNOULLI DISTRIBUTION
        y_mean_normalized = y_mean;
        link_gradient_normalized = link_gradient;
        if          (link_type == 1 & link_power == 0.0)  { # Binomial.log
            y_mean_normalized = exp (linear_terms);
            link_gradient_normalized = 1.0 / y_mean_normalized;
        } else { if (link_type == 1 & link_power != 0.0)  { # Binomial.power_nonlog
            y_mean_normalized = linear_terms ^ (1.0 / link_power);
            link_gradient_normalized = link_power * linear_terms ^ (1.0 - 1.0 / link_power);
        } else { if (link_type == 2)                      { # Binomial.logit
            y_mean_normalized = 1.0 / (1.0 + exp (- linear_terms));
            link_gradient_normalized = 2.0 + (exp (linear_terms) + exp (- linear_terms));
        } else { if (link_type == 3)                      { # Binomial.probit
            y_mean_normalized = gaussian_probability (linear_terms);
            link_gradient_normalized = 2.506628274631000502415765284811 * exp (linear_terms * linear_terms / 2.0);   #  the long number = sqrt (2 * pi)
        } else { if (link_type == 4)                      { # Binomial.cloglog
            y_mean_normalized = 1.0 - exp (- exp (linear_terms));
            link_gradient_normalized = exp (- linear_terms) / (1.0 - y_mean_normalized);
        } else { if (link_type == 5)                      { # Binomial.cauchit
            atan_linear_terms = atan_temporary (linear_terms);
            y_mean_normalized = 0.5 + atan_linear_terms / 3.1415926535897932384626433832795;
            link_gradient_normalized = (1 + linear_terms * linear_terms) * 3.1415926535897932384626433832795;
        }}}}}}
        if (dist_param == 1.0) {  # Two-column "y"
            y_mean = rowSums (y) * y_mean_normalized;
            link_gradient = link_gradient_normalized / rowSums (y);
            var_function = rowSums (y) * y_mean_normalized * (1.0 - y_mean_normalized);
        } else {  # y = bernoulli_scale * y_normalized + bernoulli_shift
            bernoulli_scale = 1.0 - dist_param;
            bernoulli_shift = dist_param;
            y_mean = bernoulli_scale * y_mean_normalized + bernoulli_shift;
            link_gradient = link_gradient_normalized / bernoulli_scale;
            var_function = (bernoulli_scale * bernoulli_scale) * y_mean_normalized * (1.0 - y_mean_normalized);
}   }   }


glm_log_likelihood_part = function (Matrix[double] linear_terms, Matrix[double] y,
        int dist_type, double dist_param, int link_type, double link_power)
    return (double log_l, int isNaN)
{
    isNaN = 0;
    log_l = 0.0;
    positive_infinity  =  1.0 / 0.0;
    negative_infinity  = -1.0 / 0.0;
    
    if (dist_type == 1 & link_type == 1)
    { # POWER DISTRIBUTION
        b_cumulant = linear_terms;
        natural_parameters = linear_terms;
        var_power = dist_param;
        if          (var_power == 1.0 & link_power ==  0.0) { # Poisson.log
            b_cumulant = exp (linear_terms);
            natural_parameters = linear_terms;
        } else { if (var_power == 1.0 & link_power ==  1.0) { # Poisson.id
            if (sum (ppred (linear_terms, 0.0, "<")) == 0) {
                b_cumulant = linear_terms;
                is_zero_linear_terms = ppred (linear_terms, 0.0, "=="); 
                natural_parameters = log (linear_terms + is_zero_linear_terms) - is_zero_linear_terms / (1.0 - is_zero_linear_terms);
            } else {isNaN = 1;}
        } else { if (var_power == 1.0 & link_power ==  0.5) { # Poisson.sqrt
            if (sum (ppred (linear_terms, 0.0, "<")) == 0) {
                b_cumulant = linear_terms * linear_terms;
                is_zero_linear_terms = ppred (linear_terms, 0.0, "=="); 
                natural_parameters = log (linear_terms + is_zero_linear_terms) - is_zero_linear_terms / (1.0 - is_zero_linear_terms);
                natural_parameters = 2.0 * natural_parameters;
            } else {isNaN = 1;}
        } else { if (var_power == 1.0 & link_power > 0.0)   { # Poisson.power_nonlog, pos
            if (sum (ppred (linear_terms, 0.0, "<")) == 0) {
                is_zero_linear_terms = ppred (linear_terms, 0.0, "=="); 
                b_cumulant = (linear_terms + is_zero_linear_terms) ^ (1.0 / link_power) - is_zero_linear_terms;
                natural_parameters = log (linear_terms + is_zero_linear_terms) - is_zero_linear_terms / (1.0 - is_zero_linear_terms);
                natural_parameters = natural_parameters / link_power;
            } else {isNaN = 1;}
        } else { if (var_power == 1.0)                      { # Poisson.power_nonlog, neg
            if (sum (ppred (linear_terms, 0.0, "<=")) == 0) {
                b_cumulant = linear_terms ^ (1.0 / link_power);
                natural_parameters = log (linear_terms) / link_power;
            } else {isNaN = 1;}
        } else { if (var_power == 2.0 & link_power == -1.0) { # Gamma.inverse
            if (sum (ppred (linear_terms, 0.0, "<=")) == 0) {
                b_cumulant = - log (linear_terms);
                natural_parameters = - linear_terms;
            } else {isNaN = 1;}
        } else { if (var_power == 2.0 & link_power ==  1.0) { # Gamma.id
            if (sum (ppred (linear_terms, 0.0, "<=")) == 0) {
                b_cumulant = log (linear_terms);
                natural_parameters = - 1.0 / linear_terms;
            } else {isNaN = 1;}
        } else { if (var_power == 2.0 & link_power ==  0.0) { # Gamma.log
            b_cumulant = linear_terms;
            natural_parameters = - exp (- linear_terms);
        } else { if (var_power == 2.0)                      { # Gamma.power_nonlog
            if (sum (ppred (linear_terms, 0.0, "<=")) == 0) {
                b_cumulant = log (linear_terms) / link_power;
                natural_parameters = - linear_terms ^ (- 1.0 / link_power);
            } else {isNaN = 1;}
        } else { if                    (link_power ==  0.0) { # PowerDist.log
            natural_parameters = exp (linear_terms * (1.0 - var_power)) / (1.0 - var_power);
            b_cumulant = exp (linear_terms * (2.0 - var_power)) / (2.0 - var_power);
        } else {                                              # PowerDist.power_nonlog
            if          (-2 * link_power == 1.0 - var_power) {
                natural_parameters = 1.0 / (linear_terms * linear_terms) / (1.0 - var_power);
            } else { if (-1 * link_power == 1.0 - var_power) {
                natural_parameters = 1.0 / linear_terms / (1.0 - var_power);
            } else { if (     link_power == 1.0 - var_power) {
                natural_parameters = linear_terms / (1.0 - var_power);
            } else { if ( 2 * link_power == 1.0 - var_power) {
                natural_parameters = linear_terms * linear_terms / (1.0 - var_power);
            } else {
                if (sum (ppred (linear_terms, 0.0, "<=")) == 0) {
                    power = (1.0 - var_power) / link_power;
                    natural_parameters = (linear_terms ^ power) / (1.0 - var_power);
                } else {isNaN = 1;}
            }}}}
            if          (-2 * link_power == 2.0 - var_power) {
                b_cumulant = 1.0 / (linear_terms * linear_terms) / (2.0 - var_power);
            } else { if (-1 * link_power == 2.0 - var_power) {
                b_cumulant = 1.0 / linear_terms / (2.0 - var_power);
            } else { if (     link_power == 2.0 - var_power) {
                b_cumulant = linear_terms / (2.0 - var_power);
            } else { if ( 2 * link_power == 2.0 - var_power) {
                b_cumulant = linear_terms * linear_terms / (2.0 - var_power);
            } else {
                if (sum (ppred (linear_terms, 0.0, "<=")) == 0) {
                    power = (2.0 - var_power) / link_power;
                    b_cumulant = (linear_terms ^ power) / (2.0 - var_power);
                } else {isNaN = 1;}
            }}}}
        }}}}} }}}}}
        if (isNaN == 0)
        {
            is_np_neginfinite  = ppred (natural_parameters, negative_infinity, "==") * ppred (y, 0.0, "!=");
            natural_parameters = replace(target=natural_parameters, pattern=-1/0, replacement=0); #deNegInfinity
            natural_parameters = natural_parameters - is_np_neginfinite / (1.0 - is_np_neginfinite);

            log_l = sum (y * natural_parameters - b_cumulant);
            if (log_l != log_l | (log_l == log_l + 1.0 & log_l == log_l * 2.0)) {
                isNaN = 1;
    }   }   }
    
    if (dist_type == 2 & (dist_param == -1.0 | dist_param == 0.0 | dist_param == 1.0) & link_type >= 1 & link_type <= 5)
    { # BINOMIAL/BERNOULLI DISTRIBUTION
        is_LT_pos_infinite = ppred (linear_terms, positive_infinity, "==");
        is_LT_neg_infinite = ppred (linear_terms, positive_infinity, "==");
        finite_linear_terms = replace(target=linear_terms, pattern=-1/0, replacement=0); #deNegInfinity
        minus_linear_terms = - finite_linear_terms;
        minus_linear_terms = replace(target=minus_linear_terms, pattern=-1/0, replacement=0); #deNegInfinity
        finite_linear_terms = - minus_linear_terms;
        y_prob = linear_terms;
        if          (link_type == 1 & link_power == 0.0) { # Bernoulli.log
            y_prob = exp (linear_terms);
        } else { if (link_type == 1 & link_power == 0.5) { # Bernoulli.sqrt
            y_prob = linear_terms * linear_terms;
        } else { if (link_type == 1 & link_power >  0.0) { # Bernoulli.power_nonlog pos
            if (sum (ppred (linear_terms, 0.0, "<")) == 0) {
                is_zero_linear_terms = ppred (linear_terms, 0.0, "==");
                y_prob = (linear_terms + is_zero_linear_terms) ^ (1.0 / link_power) - is_zero_linear_terms;
            } else {isNaN = 1;}
        } else { if (link_type == 1 & link_power != 0.0) { # Bernoulli.power_nonlog neg
            if (sum (ppred (linear_terms, 0.0, "<=")) == 0) {
                y_prob = linear_terms ^ (1.0 / link_power);
            } else {isNaN = 1;}
        } else { if (link_type == 2)                     { # Bernoulli.logit
            y_prob = 1.0 / (1.0 + exp (- finite_linear_terms));
            y_prob = y_prob * (1.0 - is_LT_pos_infinite - is_LT_neg_infinite) + is_LT_pos_infinite;
        } else { if (link_type == 3)                     { # Bernoulli.probit
            y_prob = gaussian_probability (finite_linear_terms);
            y_prob = y_prob * (1.0 - is_LT_pos_infinite - is_LT_neg_infinite) + is_LT_pos_infinite;
        } else { if (link_type == 4)                     { # Bernoulli.cloglog
            y_prob = 1.0 - exp (- exp (linear_terms));
        } else { if (link_type == 5)                     { # Bernoulli.cauchit
            atan_linear_terms = atan_temporary (finite_linear_terms);
            y_prob = 0.5 + atan_linear_terms / 3.1415926535897932384626433832795;
            y_prob = y_prob * (1.0 - is_LT_pos_infinite - is_LT_neg_infinite) + is_LT_pos_infinite;
        }}}}}}}}
        if (isNaN == 0) {
            y_pos = y [, 1];
            y_neg = y [, 1];
            if (dist_param != 1.0) { # Convert one-column "y" to two-column
                bernoulli_scale = 1.0 - dist_param;
                bernoulli_shift = dist_param;
                y_pos = (y - bernoulli_shift) / bernoulli_scale;
                y_neg = 1.0 - y_pos;
            } else {
                y_pos = y [, 1];
                y_neg = y [, 2];
            }
            is_zero_prob = ppred (y_prob, 0.0, "<=");
            is_one_prob  = ppred (y_prob, 1.0, ">=");
            is_log_l_neg_infinity = sum (is_zero_prob * ppred (y_pos, 0.0, ">") + is_one_prob * ppred (y_neg, 0.0, ">"));
            if (is_log_l_neg_infinity == 0.0) {
                y_prob = y_prob * (1.0 - is_zero_prob) * (1.0 - is_one_prob) + 0.5 * (is_zero_prob + is_one_prob);
                log_l = sum (y_pos * log (y_prob) + y_neg * log (1.0 - y_prob))
                      - sum ((is_zero_prob + is_one_prob) * (y_pos + y_neg)) * log (0.5);
                if (log_l != log_l | (log_l == log_l + 1.0 & log_l == log_l * 2.0)) {
                    isNaN = 1;
                }
            } else {
                log_l = -1.0 / 0.0;
                isNaN = 1;
    }   }   }
    
    if (isNaN == 1) {
        log_l = - 1.0 / 0.0; 
    }
}

