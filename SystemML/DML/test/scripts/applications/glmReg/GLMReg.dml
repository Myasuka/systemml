#-------------------------------------------------------------
# IBM Confidential
# OCO Source Materials
# (C) Copyright IBM Corp. 2010, 2013
# The source code for this program is not published or
# otherwise divested of its trade secrets, irrespective of
# what has been deposited with the U.S. Copyright Office.
#-------------------------------------------------------------


setwd ("test/scripts/applications/glmReg");
source ("Cholesky.dml");
source ("CGSteihaug.dml");
source ("Misc.dml");

# Intended to solve GLM Regression using Iteratively Reweighted Least Squares WITH TRUST REGIONS
# Assume LR_HOME is set to the home of the dml script
# Assume input and output directories are on hdfs as INPUT_DIR and OUTPUT_DIR
# INPUT 1: Matrix X [rows, columns]
# INPUT 2: number of rows
# INPUT 3: number of columns
# INPUT 4: Matrix y [rows, 1]
# INPUT 5: distribution_family: integer 00 ... 99, see the table below:
# -------------------------------------------------------------------------
#          FAMILY:   0x        1x        2x        3x        4x        9x
#   LINK:          Gaussian  Binomial  Poisson   Gamma  inv_Gaussian  Other
#   x0 = identity    00*       --        20        30        40        --
#   x1 = inverse     01        --        --        31*       41        --
#   x2 = log         02        12        22*       32        42        --
#   x3 = sqrt        --        --        23        --        --        --
#   x4 = 1/mu^2      --        --        --        --        44*       --
#   x5 = logit       --        15*       --        --        --        --
#   x6 = probit      --        16        --        --        --        --
#   x7 = cauchit     --       (17)       --        --        --        --
#   x8 = cloglog     --        18        --        --        --        --
#   x9 = other      (09)      (19)      (29)      (39)      (49)      (99)
#   (Here * denotes the natural link, () means unfinished implementation)
#   (99 = Use variance-power and link-power constants specified elsewhere)
# -------------------------------------------------------------------------
# INPUT 6: Overdispersion: 0 = Don't Fix, 1 = Fix [NOT DONE YET]
# INPUT 7: L2-regularizer (lambda)
# INPUT 8: Tolerance (epsilon)
# INPUT 9: The output file
# OUTPUT:  Matrix beta [cols, 1]
# Assume rows = 50 and cols = 30, distribution_family = 15, overdispersion = 0, lambda = 0.0, epsilon = 0.00000001
# hadoop jar SystemML.jar -f $GLMR_HOME/GLMReg.dml -args "$INPUT_DIR/X" 50 30 "$INPUT_DIR/y" 15 0 0.0 0.00000001 "$OUTPUT_DIR/beta"

print("BEGIN GLM SCRIPT");
print("Reading X...");
X = read($1, rows=$2, cols=$3, format="text");
print("Reading Y...");
y = read($4, rows=$2, cols=1, format="text");

num_records = $2;
num_features = $3;
distribution_family = $5;
overdispersion_flag = $6;
lambda_regularizer = $7;
eps = $8;

# Use the two constants below, "variance_as_power_of_the_mean" and
# "link_as_power_of_the_mean", to specify the variance and the link as arbitrary
# powers of the mean.  However, the variance-power should not equal 1.0 nor 2.0,
# because these values integrate into logarithms:
#   Variance-power of 0.0 corresponds to the Gaussian distribution (OK to use);
#   Variance-power of 1.0 corresponds to the Poisson distribution (NOT OK);
#   Variance-power of 2.0 corresponds to the Gamma distribution (NOT OK);
#   Variance-power of 3.0 corresponds to the Inverse Gaussian distribution (OK).
# By default, the link-power is set to give the canonical link.  The link-power
# of exactly 0.0 is automatically replaced by the logarithm link.
#
[updated_distribution_family, variance_as_power_of_the_mean, link_as_power_of_the_mean]
    = glm_set_default_powers_of_the_mean (distribution_family);
distribution_family = updated_distribution_family;


#####  START OF THE MAIN PART  #####

max_trust_delta = sqrt (1.0 + num_features);
trust_delta = max_trust_delta / 100.0;
max_iteration_IRLS = 100;

beta_random = Rand (rows = num_features, cols = 1, min = -1.0, max = 1.0);
[beta, sigmaLF] = scaleWeights (X, beta_random, 1.0, 0.0);
print ("Initial sigmaLF = " + sigmaLF);
g = Rand (rows = num_features, cols = 1, min = 0, max = 0);
A = Rand (rows = num_features, cols = num_features, min = 0, max = 0);
log_l = 0.0;
isNaN_log_l = 2;
newbeta = beta;
accept_new_beta = 1;
reached_trust_boundary = 0;
neg_log_l_change_predicted = 0.0;
converged_IRLS = 0;
i_IRLS = 0;

print ("BEGIN IRLS ITERATIONS...");

all_linear_terms = X %*% newbeta;

[new_log_l, isNaN_new_log_l] = glm_log_likelihood_part
    (distribution_family, all_linear_terms, y, variance_as_power_of_the_mean, link_as_power_of_the_mean);

if (isNaN_new_log_l == 0) {
    new_log_l = new_log_l - 0.5 * lambda_regularizer * sum (newbeta * newbeta);
}
                             

while (converged_IRLS == 0)
{
    accept_new_beta = 1;
    
    if (i_IRLS > 0)
    {
        if (isNaN_log_l == 0) {
            accept_new_beta = 0;
        }

# Decide whether to accept a new iteration point and update the trust region
# See Alg. 4.1 on p. 69 of "Numerical Optimization" 2nd ed. by Nocedal and Wright

        rho = (- new_log_l + log_l) / neg_log_l_change_predicted;
        if (rho < 0.25 | isNaN_new_log_l == 1) {
            trust_delta = 0.25 * trust_delta;
        }
        if (rho > 0.75 & isNaN_new_log_l == 0 & reached_trust_boundary == 1) {
            trust_delta = 2 * trust_delta;
            if (trust_delta > max_trust_delta) {
                trust_delta = max_trust_delta;
            }
        }
        if (rho > 0.1 & isNaN_new_log_l == 0) {
            accept_new_beta = 1;
        }
    }

    if (accept_new_beta == 1)
    {
        beta = newbeta;  log_l = new_log_l;  isNaN_log_l = isNaN_new_log_l;
        [y_mean, link_grad, y_var] = 
            glm_dist (distribution_family, all_linear_terms, variance_as_power_of_the_mean, link_as_power_of_the_mean);
                      
norm_y_mean = sqrt (sum (y_mean * y_mean));
norm_y_var = sqrt (sum (y_var * y_var));
norm_link_grad = sqrt (sum (link_grad * link_grad));
min_linear_term = min (all_linear_terms);
max_linear_term = max (all_linear_terms);
print ("||y_mean|| = " + norm_y_mean + ";  ||y_var|| = " + norm_y_var + ";  ||link_grad|| = " + norm_link_grad + ";  max_linear_term = " + max_linear_term);                      
                      
        aux_diag = Rand (rows = num_records, cols = 1, min = 1.0, max = 1.0);
        aux_diag = (aux_diag / y_var) / link_grad;
        g = - t(X) %*% (aux_diag * (y - y_mean));
        w_diag = aux_diag / link_grad;
        A = t(X) %*% diag (w_diag) %*% X;
    }
    
    [z, neg_log_l_change_predicted, reached_trust_boundary] = 
        get_CG_Steihaug_point (A, g, beta, trust_delta, lambda_regularizer);

    newbeta = beta + z;
    
    all_linear_terms = X %*% newbeta;
    
    [new_log_l, isNaN_new_log_l] = glm_log_likelihood_part
        (distribution_family, all_linear_terms, y, variance_as_power_of_the_mean, link_as_power_of_the_mean);

    if (isNaN_new_log_l == 0) {
        new_log_l = new_log_l - 0.5 * lambda_regularizer * sum (newbeta * newbeta);
    }
        
    log_l_change = new_log_l - log_l;

    if (reached_trust_boundary == 0 & isNaN_new_log_l == 0 & 
        (abs (log_l_change) < eps | abs (log_l_change) < (abs (log_l) + abs (new_log_l)) * 0.00000000000001) )  
    {
        converged_IRLS = 1;
    }
    rho = - log_l_change / neg_log_l_change_predicted;
    z_norm = sqrt(sum (z * z));
    [z_norm_to_print] = round_to_print (z_norm);
    [trust_delta_to_print] = round_to_print (trust_delta);
    [rho_to_print] = round_to_print (rho);
    [new_log_l_to_print] = round_to_print (new_log_l);
    [log_l_change_to_print] = round_to_print (log_l_change);
    g_norm = sqrt(sum (g * g))
    [g_norm_to_print] = round_to_print (g_norm);

    i_IRLS = i_IRLS + 1;
    print ("Iter #" + i_IRLS + " completed, ||z|| = " + z_norm_to_print + ", trust_delta = " + 
        trust_delta_to_print + ", reached = " + reached_trust_boundary +
        ", ||g|| = " + g_norm_to_print + 
        ", new_log_l = " + new_log_l_to_print + 
        ", log_l_change = " + log_l_change_to_print + 
        ", rho = " + rho_to_print);
    if (i_IRLS == max_iteration_IRLS) {
        converged_IRLS = 2;
    }
}

beta = newbeta;
log_l = new_log_l;

if(converged_IRLS == 1) {
    print("Converged in " + i_IRLS + " steps.");
}
else {
    print("Did not converge.");
}

print ("beta[1] = " + castAsScalar(beta[1, 1]));
print ("beta[2] = " + castAsScalar(beta[2, 1]));
print ("beta[3] = " + castAsScalar(beta[3, 1]));


write (beta, $9, format="text");



#####  OVER-DISPERSION PART  #####



scale_parameter = 1.0;
if (overdispersion_flag > 0.000000001)
{
    all_linear_terms = X %*% beta;
    [y_mean, link_grad, y_var] = 
        glm_dist (distribution_family, all_linear_terms, variance_as_power_of_the_mean, link_as_power_of_the_mean);
    pearson_residuals = (y - y_mean) / sqrt (y_var);
    scale_parameter = sum (pearson_residuals * pearson_residuals) / (num_records - num_features);
    
    print ("Estimated scale parameter = " + scale_parameter);
}

log_l = log_l / scale_parameter;



#####  END OF THE MAIN PART  #####


glm_set_default_powers_of_the_mean = function (int dist_family) 
    return (int new_dist_family, double variance_power, double link_power)
{
    new_dist_family = dist_family;
    variance_power = 3.0;
    link_power = 1.0 - variance_power;
    if (dist_family == 00) # Gaussian.id
    {
        variance_power = 0.0;
        link_power = 1.0;
        new_dist_family = 99;
    }
    if (dist_family == 01) # Gaussian.inverse
    {
        variance_power = 0.0;
        link_power = -1.0;
        new_dist_family = 99;
    }
    if (dist_family == 02) # Gaussian.log
    {
        variance_power = 0.0;
        link_power = 0.0;
        new_dist_family = 99;
    }
    if (dist_family == 44) # inv_Gaussian.1/mu^2
    {
        variance_power = 3.0;
        link_power = -2.0;
        new_dist_family = 99;
    }
    if (dist_family == 40) # inv_Gaussian.id
    {
        variance_power = 3.0;
        link_power = 1.0;
        new_dist_family = 99;
    }
    if (dist_family == 41) # inv_Gaussian.inverse
    {
        variance_power = 3.0;
        link_power = -1.0;
        new_dist_family = 99;
    }
    if (dist_family == 42) # inv_Gaussian.log
    {
        variance_power = 3.0;
        link_power = 0.0;
        new_dist_family = 99;
    }
}

glm_log_likelihood_part = 
    function (int dist_family, Matrix[double] linear_terms, Matrix[double] y, double var_pow_m, double lnk_pow_m)
    return (double log_l, int isNaN)
{
    isNaN = 0;
    y_corr = y;
    b_cumulant = linear_terms;
    natural_parameters = linear_terms;
    
    if (dist_family == 15) # Bernoulli.logit
    {
        b_cumulant = log (1.0 + exp (linear_terms));
        natural_parameters = linear_terms;
        y_corr = (y + 1) / 2.0;
    } else {
    if (dist_family == 16) # Bernoulli.probit
    {
        temp0 = gaussian_probability (linear_terms);
        temp1 = 1.0 - temp0;
        if (sum (ppred (temp1, 0.0, "<=")) == 0) {
            b_cumulant = - log (temp1);
            natural_parameters = log (temp0) + b_cumulant;
            y_corr = (y + 1) / 2.0;
        } else {
            isNaN = 1;
        }
    } else {
    if (dist_family == 12) # Bernoulli.log
    {
        temp1 = 1.0 - exp (linear_terms);
        if (sum (ppred (temp1, 0.0, "<=")) == 0) {
            b_cumulant = - log (temp1);
            natural_parameters = linear_terms + b_cumulant;
            y_corr = (y + 1) / 2.0;
        } else {
            isNaN = 1;
        }
    } else {
    if (dist_family == 18) # Bernoulli.cloglog
    {
        b_cumulant = exp (linear_terms);
        natural_parameters = b_cumulant + log (1 - exp (- b_cumulant));
        y_corr = (y + 1) / 2.0;
    } else {
    if (dist_family == 22) # Poisson.log
    {
        b_cumulant = exp (linear_terms);
        natural_parameters = linear_terms;
    } else {
    if (dist_family == 20) # Poisson.id
    {
        if (sum (ppred (linear_terms, 0.0, "<=")) == 0) {
            b_cumulant = linear_terms;
            natural_parameters = log (linear_terms);
        } else {
            isNaN = 1;
        }
    } else {
    if (dist_family == 23) # Poisson.sqrt
    {
        if (sum (ppred (linear_terms, 0.0, "<=")) == 0) {
            b_cumulant = linear_terms * linear_terms;
            natural_parameters = 2 * log (linear_terms);
        } else {
            isNaN = 1;
        }
    } else {
    if (dist_family == 31) # Gamma.inverse
    {
        if (sum (ppred (linear_terms, 0, "<=")) == 0) {
            b_cumulant = - log (linear_terms);
            natural_parameters = - linear_terms;
        } else {
            isNaN = 1;
        } 
    } else {
    if (dist_family == 30) # Gamma.id
    {
        if (sum (ppred (linear_terms, 0, "<=")) == 0) {
            b_cumulant = log (linear_terms);
            natural_parameters = - 1.0 / linear_terms;
        } else {
            isNaN = 1;
        } 
    } else {
    if (dist_family == 32) # Gamma.log
    {
        b_cumulant = linear_terms;
        natural_parameters = - exp (- linear_terms);
    } else {
    if (dist_family == 99) # Using variance-power and link-power
    {
        if (lnk_pow_m == 0.0)
        {
            natural_parameters = exp (linear_terms * (1.0 - var_pow_m)) / (1.0 - var_pow_m);
            b_cumulant = exp (linear_terms * (2.0 - var_pow_m)) / (2.0 - var_pow_m);
        } else {
            power = (1.0 - var_pow_m) / lnk_pow_m;
            if (-2.00000000000001 < power & power < -1.99999999999999) {
                natural_parameters = 1.0 / (linear_terms * linear_terms) / (1.0 - var_pow_m);
            } else {
            if (-1.00000000000001 < power & power < -0.99999999999999) {
                natural_parameters = 1.0 / linear_terms / (1.0 - var_pow_m);
            } else {
            if ( 0.99999999999999 < power & power <  1.00000000000001) {
                natural_parameters = linear_terms / (1.0 - var_pow_m);
            } else {
            if ( 1.99999999999999 < power & power <  2.00000000000001) {
                natural_parameters = linear_terms * linear_terms / (1.0 - var_pow_m);
            } else {
                natural_parameters = (linear_terms ^ power) / (1.0 - var_pow_m);
            }}}}
            power = (2.0 - var_pow_m) / lnk_pow_m;
            if (-2.00000000000001 < power & power < -1.99999999999999) {
                b_cumulant = 1.0 / (linear_terms * linear_terms) / (2.0 - var_pow_m);
            } else {
            if (-1.00000000000001 < power & power < -0.99999999999999) {
                b_cumulant = 1.0 / linear_terms / (2.0 - var_pow_m);
            } else {
            if ( 0.99999999999999 < power & power <  1.00000000000001) {
                b_cumulant = linear_terms / (2.0 - var_pow_m);
            } else {
            if ( 1.99999999999999 < power & power <  2.00000000000001) {
                b_cumulant = linear_terms * linear_terms / (2.0 - var_pow_m);
            } else {
                b_cumulant = (linear_terms ^ power) / (2.0 - var_pow_m);
        }   }}}}
    } else {
        natural_parameters = linear_terms;
        b_cumulant = linear_terms * linear_terms / 2.0;
    }}}}} }}}}} }
    log_l = 0.0;
    if (isNaN == 0) {
        log_l = sum (y_corr * natural_parameters - b_cumulant);
        
        if (log_l == log_l) {
            if (log_l == (log_l + 1.0) & log_l == (log_l * 2.0)) {
                isNaN = 1;
            }
        } else {
            isNaN = 1;
        }
    }
    if (isNaN == 1) {
        log_l = - 1.0 / 0.0; 
    }
}


glm_dist = 
    function (int dist_family, Matrix[double] linear_terms, double var_pow_m, double lnk_pow_m) 
    return (Matrix[double] mean, Matrix[double] link_gradient, Matrix[double] var_function)
    # NOTE: var_function is the variance without dispersion, i.e. the V(mu) function.
{
    mean = linear_terms;
    link_gradient = Rand (rows = nrow (linear_terms), cols = 1, min = 1.0, max = 1.0);
    var_function = link_gradient;
    if (dist_family == 15) # Bernoulli.logit
    {
        mean = 2.0 / (1.0 + exp (- linear_terms)) - 1.0;
        link_gradient = 1.0 + (exp (linear_terms) + exp (- linear_terms)) / 2.0;
        var_function = 2.0 / link_gradient;
    } else {
    if (dist_family == 16) # Bernoulli.probit
    {
        # y_normalized = (y + 1.0) / 2.0;  y = 2.0 * y_normalized - 1.0;
        gp_terms = gaussian_probability (linear_terms);
        mean = 2.0 * gp_terms - 1.0;
        link_gradient = (2.506628274631000502415765284811 * exp (linear_terms * linear_terms / 2.0)) / 2.0;   #  the long number = sqrt (2 * pi)
        var_function = 4.0 * gp_terms * (1.0 - gp_terms);
    } else {
    if (dist_family == 12) # Bernoulli.log
    {
        # y_normalized = (y + 1.0) / 2.0;  y = 2.0 * y_normalized - 1.0;
        mean = 2.0 * (exp (linear_terms)) - 1.0;
        link_gradient = - log (1.0 - exp (linear_terms)) / 2.0;
        var_function = 4.0 * (exp (linear_terms) / (1.0 - exp (linear_terms)));
    } else {
    if (dist_family == 18) # Bernoulli.cloglog
    {
        # y_normalized = (y + 1.0) / 2.0;  y = 2.0 * y_normalized - 1.0;
        mean = 2.0 * (1.0 - exp (- exp (linear_terms))) - 1.0;
        link_gradient = (exp (linear_terms) + log (1.0 - exp (- exp (linear_terms)))) / 2.0;
        var_function = 4.0 * (1.0 - exp (- exp (linear_terms))) * exp (- exp (linear_terms));
    } else {
    if (dist_family == 22) # Poisson.log
    {
        mean = exp (linear_terms);
        link_gradient = exp (- linear_terms);
        var_function = mean;
    } else {
    if (dist_family == 20) # Poisson.id
    {
        mean = linear_terms;
        link_gradient = Rand (rows = nrow (linear_terms), cols = 1, min = 1.0, max = 1.0);
        var_function = linear_terms;
    } else {
    if (dist_family == 23) # Poisson.sqrt
    {
        mean = linear_terms * linear_terms;
        link_gradient = 0.5 / linear_terms;
        var_function = mean;
    } else {
    if (dist_family == 31) # Gamma.inverse
    {
        mean = 1.0 / linear_terms;
        link_gradient = - linear_terms * linear_terms;
        var_function = mean * mean;
    } else {
    if (dist_family == 30) # Gamma.id
    {
        mean = linear_terms;
        link_gradient = Rand (rows = nrow (linear_terms), cols = 1, min = 1.0, max = 1.0);
        var_function = linear_terms * linear_terms;
    } else {
    if (dist_family == 32) # Gamma.log
    {
        mean = exp (linear_terms);
        link_gradient = exp (- linear_terms);
        var_function = mean * mean;
    } else {
    if (dist_family == 99) # Using variance-power and link-power
    {
        if (-1.00000000000001 < lnk_pow_m & lnk_pow_m < -0.99999999999999) {
            mean = 1.0 / linear_terms;
            link_gradient = - linear_terms * linear_terms;
        } else {
        if (-0.00000000000001 < lnk_pow_m & lnk_pow_m <  0.00000000000001) {
            mean = exp (linear_terms);
            link_gradient = exp (- linear_terms);
        } else {
        if ( 0.99999999999999 < lnk_pow_m & lnk_pow_m <  1.00000000000001) {
            mean = linear_terms;
            link_gradient = Rand (rows = nrow (linear_terms), cols = 1, min = 1.0, max = 1.0);
        } else {
            mean = linear_terms ^ (1.0 / lnk_pow_m);
            link_gradient = lnk_pow_m * linear_terms ^ (1.0 - 1.0 / lnk_pow_m);
        }}}
        if (-0.00000000000001 < var_pow_m & var_pow_m <  0.00000000000001) {
            var_function = Rand (rows = nrow(mean), cols = 1, min = 1.0, max = 1.0);
        } else {
        if ( 2.99999999999999 < var_pow_m & var_pow_m <  3.00000000000001) {
            var_function = mean * mean * mean;
        } else {
            var_function = mean ^ var_pow_m;
        }}
    } else {
        mean = linear_terms;
        link_gradient = 1.0 + 0.0 * mean;
        var_function = link_gradient;
    }}}}} }}}}} }
}


