
addClassPath("lib/metaDataParse.jar");
eval = javaudf("com.ibm.systemML.dataTransformation.metaDataParse");

jsonLines = fn(location)
    lines ( location,
        inoptions = { converter: "com.ibm.jaql.io.hadoop.converter.FromJsonTextConverter"},
        outoptions = { converter: "com.ibm.jaql.io.hadoop.converter.ToJsonTextConverter"});

// --------------------------------------------------------------------------------
// Read the input data in delimited format
// This is the case when the user provides a CSV format input file
// --------------------------------------------------------------------------------

getInput = fn(input, metadataMem) (
   
  if (metadataMem == [])
  (
     // Can we just read the first line of the file? 
     inputLine = read(lines(input)),
     inputFields = strSplit(inputLine[1], ", *"),
     
	 numCols = inputFields -> count(),
	 
	 //If CSV file does not have column names, we need to generate it
	 //TODO: if the CSV file has column names, we need to read the first line of the file
	 names = range(1, numCols) 
	               -> transform strcat("C",serialize($)) 
	               -> enumerate() 
	               -> transform {"attributeColumnId": $[0]+1, "attributeName": $[1]},
	


	 // We determine the kind of each attribute by using a regular expression test
     doubleReg = regex ("^[-]?([0-9]*[.][0-9]+)$"),
     longReg = regex ("^[-]?([0]|[1-9][0-9]*)$"),
     
	 types = inputFields -> transform if (regex_test (longReg, $)) 
	                            { attributeType: "long" } 
	                            else if (regex_test (doubleReg, $))
	                            { attributeType: "double" }
	                            else 
	                            { attributeType: "string" }
                   -> transform values($)
                   -> expand 
                   -> enumerate() 
                   -> transform {"attributeColumnId": $[0]+1, "attributeType": $[1]},
     
     // Now we create an array of metaAttributes that has column ID, name, and type              
     join names, types where names.attributeColumnId == types.attributeColumnId 
                      into {names.attributeColumnId, names.attributeName, types.attributeType} 
                      -> sort by [$.attributeColumnId]

  	 
  )
  else
  (
     // If a user provides a metadata file, it should at least offer attribute name and attribute type
     // for each column. We will compute the other attributes later.
     // TODO: if a user provided metadata file does not have attributeType/attributeName information
     
     metadataMem -> transform {$.attributeName, $.attributeType} 
     -> enumerate() 
     -> transform {"attributeColumnId": $[0]+1, $[1]}
     -> sort by [$.attributeColumnId]
  )
);

writeCSVToJson = fn(input, inputDelimiter, metaAttributes, output)
(
    schemaString = metaAttributes 
                   -> transform { "text": strcat($.attributeName,":",$.attributeType)} 
                   -> transform values($) 
                   -> expand 
                   -> strJoin(","),
    
     // schema of the input
     inputSchema = "schema {" + schemaString + "}",
     
     inputArray = if (isnull(inputDelimiter))
     (
	    read (del(location=input, 
	    		schema = eval(inputSchema) ) )
     )
     else
     (
	    read (del(location=input, delimiter=inputDelimiter,
				schema = eval(inputSchema) ) )
     ),
     
     inputArray 
         -> write(jsonLines(output))
);

//
// Generate json file column id
//

genJsonColumnMeta = fn (inputData, metadataMem)
(
   if (metadataMem == [])
   (
      
      // We determine the kind of each attribute by using a regular expression test
      doubleReg = regex ("^[-]?([0-9]*[.][0-9]+)$"),
      longReg = regex ("^[-]?([0]|[1-9][0-9]*)$"),
   
      inputData
      -> top 1 -> transform pairwise (names($), values($)) -> expand -> enumerate() 
	  -> transform { "attributeColumnId": $[0]+1, "attributeName":index($[1],0),
	                 "attributeType": (if (regex_test (longReg, serialize(index($[1],1))))
                     "long"
                     else if (regex_test (doubleReg,serialize(index($[1],1))))
	                 "double" 
	                 else 
	                 "string")}
				    -> sort by [$.attributeColumnId]
	)
	else
	(
	   // If a user provides a metadata file, it should at least offer attribute name and attribute type
       // for each column. We will compute the other attributes later.
       // TODO: if a user provided metadata file does not have attributeType/attributeName information
	   metadataMem -> transform {$.attributeName, $.attributeType} 
           -> enumerate() 
           -> transform {"attributeColumnId": $[0]+1, $[1]}
           -> sort by [$.attributeColumnId]
	)
   
);


// --------------------------------------------------------------------------------
// Insert a heuristically derived value for any missing (null) attributeKind fields
// --------------------------------------------------------------------------------

genMeta = fn(columnId, metadataMem, outputMetadata) (

join orig in metadataMem, preserve new in columnId 
   where orig.attributeName == new.attributeName
   into {
      new.attributeName,
      "attributeColumnId":(if (isnull(orig.attributeColumnId)) new.attributeColumnId else orig.attributeColumnId),
      "attributeKind":(if (isnull(orig.attributeKind)) "N/A" else orig.attributeKind),
      "attributeType":(if (isnull(orig.attributeType)) new.attributeType else orig.attributeType),
      //At this point, we do not calculate what's the total distinct count of values.
      "attributeDistinctCount": ("N/A")
   }
   -> sort by [$.attributeColumnId]
   -> write(jsonText(outputMetadata))

);

