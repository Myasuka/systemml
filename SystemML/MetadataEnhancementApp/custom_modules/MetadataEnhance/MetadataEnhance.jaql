
addClassPath("lib/metaDataParse.jar");
eval = javaudf("com.ibm.systemML.dataTransformation.metaDataParse");


// --------------------------------------------------------------------------------
// Read the input data in delimited format
// --------------------------------------------------------------------------------

inputData = fn(input, metadataMem, inputDelimiter) (

schemaString = metadataMem
   -> transform $.attributeName + ":" + $.attributeType
   -> strJoin(","),

// schema of the input
inputSchema = "schema {" + schemaString + "}",

inputData = if (isnull(inputDelimiter))
		  (
			read (del(location=input, 
				schema = eval(inputSchema) ) )
		  )
		  else
		  (
			read (del(location=input, delimiter=inputDelimiter,
				schema = eval(inputSchema) ) ))

);

//
// Generate metadata json file
// We do some pre-aggregation to avoid Java Heap size problem for distinct()
// in group by.
//

genMetadata = fn (inputData)
(
   inputData
      -> expand (fields($))
      -> group by d = $ 
            into { attributeName: d[0] 
                  ,num: count($) 
              }
      -> group by d = $.attributeName 
            into { attributeName: d
                  ,attributeCount: sum($[*].num)
                  ,attributeDistinctCount: count($[*].num) 
                 }
      -> group 
            into (cC = inputData->count(), cA = count($),
   	       $ -> transform each a {a.*, 
                                         caseCount: cC,
                                         countAttributes: cA
                                        }
                 ) 
      -> expand $
         // set attribute kind based on some heuristics
      -> transform if ($.attributeDistinctCount > 0.10 * $.caseCount)
                       {${*-}, attributeKind: "scale", attributeType: null} 
   		else                      
                       {${*-}, attributeKind: "nominal", attributeType: null} 
);


// --------------------------------------------------------------------------------
// Insert a heuristically derived value for any missing (null) attributeKind fields
// --------------------------------------------------------------------------------

metaEnhance = fn(inputData, metadataMem, outputMetadata) (

kindHeuristic = genMetadata (inputData),

join orig in metadataMem, new in kindHeuristic 
   where orig.attributeName == new.attributeName
   into {
      orig{*-.attributeKind},
      "attributeKind":(if (isnull(orig.attributeKind)) new.attributeKind else orig.attributeKind)
   }
   -> sort by [$.attributeColumnId]
   -> write(jsonText(outputMetadata))

);


//--------------------------------------------------------------------------------
// Recode Maps
//--------------------------------------------------------------------------------

jsonLines = fn(location)
    lines ( location,
        inoptions = { converter: "com.ibm.jaql.io.hadoop.converter.FromJsonTextConverter"},
        outoptions = { converter: "com.ibm.jaql.io.hadoop.converter.ToJsonTextConverter"});

genRcdMap = fn (inputData, attrs, outFile) (

   keep = (attrs -> filter $.attributeKind != "scale")[*].attributeName,
   inputData
   -> expand (fields($))
   -> filter $[0] in keep
   -> group by d = $ into d
   -> group by aN = $[0] as dVals into (
         x = dVals[*][1] -> filter not isnull $,	      
         attrKind = singleton(attrs -> filter $.attributeName == aN).attributeKind,
         if (attrKind != "ordinal") (
               x 
             ) else (
               x -> sort by [$ desc]
             )
             -> enumerate()
             -> transform {attributeName: aN, recodeId: $[0] + 1, catValue: $[1]} 
      )
   -> expand
   -> write(jsonLines(outFile))

);
